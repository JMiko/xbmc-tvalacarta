# -*- coding: utf-8 -*-#------------------------------------------------------------# pelisalacarta - XBMC Plugin# Canal para http://www.conectate.gov.ar# creado por rsantaella# http://blog.tvalacarta.info/plugin-xbmc/pelisalacarta/#------------------------------------------------------------import urlparse,urllib2,urllib,reimport os, sysfrom core import loggerfrom core import configfrom core import scrapertoolsfrom core.item import Itemfrom servers import servertools__channel__ = "conectate"__category__ = "F"__type__ = "generic"__title__ = "conectate"__language__ = "ES"__creationdate__ = "20121130"DEBUG = config.get_setting("debug")def isGeneric():    return Truedef mainlist(item):    logger.info("tvalacarta.channels.conectate mainlist")       itemlist = []    itemlist.append( Item(channel=__channel__, title="Encuentro", action="secciones", url="http://www.conectate.gob.ar/sitios/conectate/busqueda/encuentro"))     itemlist.append( Item(channel=__channel__, title="Pakapaka", action="secciones", url="http://www.conectate.gob.ar/sitios/conectate/busqueda/pakapaka"))     itemlist.append( Item(channel=__channel__, title="DEPORTV", action="secciones", url="http://www.conectate.gob.ar/sitios/conectate/busqueda/deportv"))    itemlist.append( Item(channel=__channel__, title="Educ.ar", action="secciones", url="http://www.conectate.gob.ar/sitios/conectate/busqueda/educar"))    itemlist.append( Item(channel=__channel__, title="Conectar igualdad", action="secciones", url="http://www.conectate.gob.ar/sitios/conectate/busqueda/conectar"))    return itemlistdef secciones(item):    logger.info("tvalacarta.channels.secciones mainlist")       itemlist = []    headers = []    headers.append(["Accept","text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8"])    headers.append(["Accept-Encoding","gzip,deflate"])    headers.append(["Accept-Language","es-ES,es;q=0.8,en;q=0.6"])    headers.append(["Connection","keep-alive"])    headers.append(["User-Agent","Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/33.0.1750.152 Safari/537.36"])    reintentos = 5    while reintentos>0:        data = scrapertools.cache_page(item.url,headers=headers,timeout=5)        if data!="":            break        logger.info("tvalacarta.channels.conectate.secciones Respuesta vacia, reintentando")            reintentos = reintentos - 1    logger.info("data="+data)    bloque = scrapertools.find_single_match(data,'<h2 class="audible">Secciones</h2>(.*?)</ul>')    logger.info("bloque="+bloque)    patron = '<li class="menu-item[^<]+<a class="Menu-link" href="([^"]+)">([^<]+)</a>'    matches = re.compile(patron,re.DOTALL).findall(bloque)    for scrapedurl,scrapedtitle in matches:        url = urlparse.urljoin(item.url,scrapedurl)        thumbnail = ""        title = scrapedtitle        plot = ""        itemlist.append( Item(channel=__channel__, action="programas", title=title , url=url , thumbnail=thumbnail , fanart=thumbnail,  plot=plot , viewmode="movie_with_plot", folder=True) )    return itemlistdef programas(item):    logger.info("tvalacarta.channels.conectate programas")    # Descarga la pagina    headers = []    headers.append(["Accept","text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8"])    headers.append(["Accept-Encoding","gzip,deflate"])    headers.append(["Accept-Language","es-ES,es;q=0.8,en;q=0.6"])    headers.append(["Connection","keep-alive"])    headers.append(["Referer",item.url])    headers.append(["User-Agent","Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/33.0.1750.152 Safari/537.36"])    reintentos = 5    while reintentos>0:        data = scrapertools.cache_page(item.url,headers=headers,timeout=5)        if data!="":            break        logger.info("tvalacarta.channels.conectate.capitulos Respuesta vacia, reintentando")            reintentos = reintentos - 1    patron  = '<li class="col-xs-3"[^<]+'    patron += '<div class="card"[^<]+'    patron += '<a href="([^"]+)"[^<]+'    patron += '<img class="" height="\d+" width="\d+" src="([^"]+)"/[^<]+'    patron += '<h5>([^<]+)</h5[^<]+'    patron += '</a[^<]+'    patron += '<p>([^<]+)</p'    matches = re.compile(patron,re.DOTALL).findall(data)    itemlist = []    for scrapedurl,scrapedthumbnail,scrapedtitle,scrapedplot in matches:        url = urlparse.urljoin(item.url,scrapedurl)        thumbnail = urlparse.urljoin(item.url,scrapedthumbnail)        title = scrapedtitle        plot = scrapedplot        if (item.title == "Película") or (item.title == "Especial"):            itemlist.append( Item(channel=__channel__, action="play", server="conectate", title=title , url=url , thumbnail=thumbnail , fanart=thumbnail,  plot=plot , viewmode="movie_with_plot", folder=False) )        else:            itemlist.append( Item(channel=__channel__, action="episodios", title=title , url=url , thumbnail=thumbnail , fanart=thumbnail,  plot=plot , viewmode="movie_with_plot", folder=True) )    #http://www.conectate.gob.ar/sitios/conectate/busqueda/encuentro?rec_tipo_funcional_id=11&amp;limit=12&amp;offset=12    next_page_url = scrapertools.find_single_match(data,'<a class="menu-link" id="nextPage" class="siguiente" href="([^"]+)"[^>]+>Siguiente</a>')    if next_page_url!="":        next_page_url = urlparse.urljoin(item.url,next_page_url.replace("&amp;","&"))        logger.info("next_page_url="+next_page_url)        itemlist.append( Item(channel=__channel__, action="programas", title=">> Página siguiente" , url=next_page_url ,  folder=True) )    return itemlist	def episodios(item):    logger.info("tvalacarta.channels.conectate episodios")        itemlist = []    # Descarga la pagina    headers = []    headers.append(["Accept","text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8"])    headers.append(["Accept-Encoding","gzip,deflate"])    headers.append(["Accept-Language","es-ES,es;q=0.8,en;q=0.6"])    headers.append(["Connection","keep-alive"])    headers.append(["Referer",item.url])    headers.append(["User-Agent","Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/33.0.1750.152 Safari/537.36"])    reintentos = 5    while reintentos>0:        data = scrapertools.cachePage(item.url,headers=headers,timeout=5)        if data!="":            break        logger.info("tvalacarta.channels.conectate.episodios Respuesta vacia, reintentando")            reintentos = reintentos - 1    data = scrapertools.find_single_match(data,'<ul class="capitulos(.*?)</ul>')    patron = '<li[^<]+<a href="([^"]+)"[^>]+>([^<]+)</a>'    matches = re.compile(patron,re.DOTALL).findall(data)	    for scrapedurl,scrapedtitle in matches:        url = scrapedurl        title = scrapertools.htmlclean(scrapedtitle)		        itemlist.append( Item(channel=__channel__, action="play", server="conectate", title=title , url=url ,  folder=False) )    if len(itemlist)==0:        itemlist.append( Item(channel=__channel__, action="play", server="conectate", title="Ver este vídeo" , url=item.url ,  folder=False) )    return itemlist# Verificación automática de canales: Esta función debe devolver "True" si todo está ok en el canal.def test():        # El canal tiene estructura programas -> episodios -> play    items = mainlist(Item())    items_secciones = secciones(items[0])    for item_seccion in items_secciones:        if item_seccion.title=="Serie":            items_programas = programas(item_seccion)            if len(items_programas)==0:                print "No hay programas en "+items_secciones[0].tostring()                return False            items_episodios = episodios(items_programas[0])            if len(items_episodios)==0:                print "No hay episodios en "+items_programas[0].tostring()                return False            break    return True